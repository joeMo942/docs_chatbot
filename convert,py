import os
from bs4 import BeautifulSoup

SOURCE_HTML_DIR = "docs"
OUTPUT_TXT_DIR = "docs_files"

os.makedirs(OUTPUT_TXT_DIR, exist_ok=True)
print(f"Starting conversion from '{SOURCE_HTML_DIR}' to '{OUTPUT_TXT_DIR}'...")

for root, dirs, files in os.walk(SOURCE_HTML_DIR):
    for file in files:
        if file.endswith((".html", ".htm")):
            html_file_path = os.path.join(root, file)

            try:
                with open(html_file_path, "r", encoding="utf-8", errors="ignore") as f:
                    soup = BeautifulSoup(f.read(), "lxml")

                # This is the key: find the main content.
                # This logic is a guess for what works best for *most* doc sites.
                # For cppreference, 'bodyContent' is good. For others, 'main' or 'article'.
                main_content = soup.find("div", id="bodyContent") or \
                               soup.find("main") or \
                               soup.find("article") or \
                               soup.body

                if not main_content:
                    main_content = soup # Fallback to the whole page

                text_content = main_content.get_text(separator=" ", strip=True)

                if text_content:
                    # Create a unique .txt filename
                    relative_path = os.path.relpath(html_file_path, SOURCE_HTML_DIR)
                    txt_filename = os.path.splitext(relative_path)[0].replace(os.sep, "_") + ".txt"
                    txt_file_path = os.path.join(OUTPUT_TXT_DIR, txt_filename)

                    with open(txt_file_path, "w", encoding="utf-8") as out:
                        out.write(text_content)

            except Exception as e:
                print(f"SKIPPED: {html_file_path} (Error: {e})")

print(f"\nConversion complete. Your .txt files are ready in '{OUTPUT_TXT_DIR}'.")